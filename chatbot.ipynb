{"metadata":{"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import io\nimport random\nimport string # to process standard python strings\nimport warnings\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install nltk","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting nltk\n  Downloading nltk-3.5.zip (1.4 MB)\n\u001b[K     |████████████████████████████████| 1.4 MB 3.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: click in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (7.1.2)\nRequirement already satisfied: joblib in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nltk) (0.16.0)\nCollecting regex\n  Downloading regex-2020.7.14-cp37-cp37m-manylinux2010_x86_64.whl (660 kB)\n\u001b[K     |████████████████████████████████| 660 kB 19.4 MB/s eta 0:00:01\n\u001b[?25hCollecting tqdm\n  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n\u001b[K     |████████████████████████████████| 69 kB 9.6 MB/s  eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: nltk\n  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434677 sha256=8aea64420bb15879eda236b3c95b8bc861f5e5e6899ce8f6dff6b556cfacd669\n  Stored in directory: /home/jovyan/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\nSuccessfully built nltk\nInstalling collected packages: regex, tqdm, nltk\nSuccessfully installed nltk-3.5 regex-2020.7.14 tqdm-4.49.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('popular', quiet=True) # for downloading packages\n#nltk.download('punkt') # first-time use only\n#nltk.download('wordnet') # first-time use only","metadata":{"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"\nf=open('chatbot.txt','r',errors = 'ignore')\nraw=f.read()\nraw = raw.lower()# converts to lowercase","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \nword_tokens = nltk.word_tokenize(raw)# converts to list of words","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"lemmer = nltk.stem.WordNetLemmatizer()\n#WordNet is a semantically-oriented dictionary of English included in NLTK.\ndef LemTokens(tokens):\n    return [lemmer.lemmatize(token) for token in tokens]\nremove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n\ndef LemNormalize(text):\n    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\nGREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\ndef greeting(sentence):\n \n    for word in sentence.split():\n        if word.lower() in GREETING_INPUTS:\n            return random.choice(GREETING_RESPONSES)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def response(user_response):\n    robo_response=''\n    sent_tokens.append(user_response)\n    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n    tfidf = TfidfVec.fit_transform(sent_tokens)\n    vals = cosine_similarity(tfidf[-1], tfidf)\n    idx=vals.argsort()[0][-2]\n    flat = vals.flatten()\n    flat.sort()\n    req_tfidf = flat[-2]\n    if(req_tfidf==0):\n        robo_response=robo_response+\"I am sorry! I don't understand you\"\n        return robo_response\n    else:\n        robo_response = robo_response+sent_tokens[idx]\n        return robo_response","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"flag=True\nprint(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\nwhile(flag==True):\n    user_response = input()\n    user_response=user_response.lower()\n    if(user_response!='bye'):\n        if(user_response=='thanks' or user_response=='thank you' ):\n            flag=False\n            print(\"ROBO: You are welcome..\")\n        else:\n            if(greeting(user_response)!=None):\n                print(\"ROBO: \"+greeting(user_response))\n            else:\n                print(\"ROBO: \",end=\"\")\n                print(response(user_response))\n                sent_tokens.remove(user_response)\n    else:\n        flag=False\n        print(\"ROBO: Bye! take care..\")","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" Hi \n"},{"name":"stdout","text":"ROBO: hello\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" How are you\n"},{"name":"stdout","text":"ROBO: I am sorry! I don't understand you\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" who are you\n"},{"name":"stdout","text":"ROBO: I am sorry! I don't understand you\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" can you help me\n"},{"name":"stdout","text":"ROBO: thus, for example, online help systems can usefully employ chatbot techniques to identify the area of help that users require, potentially providing a \"friendlier\" interface than a more formal search or menu system.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" what are you doing\n"},{"name":"stdout","text":"ROBO: in 1984, a book called the policeman's beard is half constructed was published, allegedly written by the chatbot racter (though the program as released would not have been capable of doing so).\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":" what are you saying\n"},{"name":"stdout","text":"ROBO: I am sorry! I don't understand you\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}